{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Tweetsumm dataset\n",
    "This notebook is used to obtain structured JSON files that can be used as input for the Comet model.\n",
    "The output files have the following structure\n",
    "- ```train_dialogs```, ```test_dialogs``` and ```val_dialogs``` are dictionaries where each key is the unique ID of a conversation and the corresponding value is a list of the sentences of that conversation (for each sentence we kept track of its original text and the author of that sentence)\n",
    "- ```train_summaries```, ```test_summaries``` and ```val_summaries``` are dictionaries the keys are again the IDs of the conversations and each value contains one of the given summaries as a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Teresa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset of all the tweets\n",
    "df = pd.read_csv('datasets/all_tweets/twcs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2811774/2811774 [05:33<00:00, 8427.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>[@115712 I understand., I would like to assist...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>[@sprintcare and how do you propose we do that]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>[@sprintcare I have sent several private messa...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>[@115712 Please send us a Private Message so t...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>[@sprintcare I did.]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  [@115712 I understand., I would like to assist...                 2   \n",
       "1    [@sprintcare and how do you propose we do that]               NaN   \n",
       "2  [@sprintcare I have sent several private messa...                 1   \n",
       "3  [@115712 Please send us a Private Message so t...                 3   \n",
       "4                               [@sprintcare I did.]                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# apply the function to the 'text' column \n",
    "# and tokenize the text into sentences\n",
    "df[\"text\"] = df[\"text\"].apply(remove_urls)\n",
    "df[\"text\"] = df[\"text\"].progress_apply(lambda x: sent_tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, and validation sumamries \n",
    "train_tw = []\n",
    "with jsonlines.open('datasets/tweetsumm/train_tweetsum.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        train_tw.append(obj)\n",
    "\n",
    "test_tw = []\n",
    "with jsonlines.open('datasets/tweetsumm/test_tweetsum.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        test_tw.append(obj)\n",
    "\n",
    "val_tw = []\n",
    "with jsonlines.open('datasets/tweetsumm/valid_tweetsum.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        val_tw.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train dialogues:  879\n",
      "number of test dialogues:  110\n",
      "number of val dialogues:  110\n"
     ]
    }
   ],
   "source": [
    "print('number of train dialogues: ', len(train_tw))\n",
    "print('number of test dialogues: ', len(test_tw))\n",
    "print('number of val dialogues: ', len(val_tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conversation_id', 'tweet_ids_sentence_offset', 'annotations'])\n",
      "conversation_id : b065262210783596c1fe79466b8f8985\n",
      "tweet_ids_sentence_offset : [{'tweet_id': 87076, 'sentence_offsets': ['[0, 140]', '[141, 151]', '[152, 175]']}, {'tweet_id': 87075, 'sentence_offsets': ['[0, 36]']}, {'tweet_id': 87074, 'sentence_offsets': ['[0, 40]', '[41, 139]']}, {'tweet_id': 87073, 'sentence_offsets': ['[0, 61]']}, {'tweet_id': 87072, 'sentence_offsets': ['[0, 18]', '[19, 87]']}, {'tweet_id': 87071, 'sentence_offsets': ['[0, 75]']}, {'tweet_id': 87070, 'sentence_offsets': ['[0, 15]', '[16, 94]', '[95, 162]']}, {'tweet_id': 87069, 'sentence_offsets': ['[0, 72]']}, {'tweet_id': 87068, 'sentence_offsets': ['[0, 55]', '[56, 134]', '[135, 211]', '[212, 235]']}]\n",
      "annotations : [{'extractive': [{'tweet_id': 87076, 'sentence_offset': '[0, 140]'}, {'tweet_id': 87074, 'sentence_offset': '[41, 139]'}, {'tweet_id': 87073, 'sentence_offset': '[0, 61]'}], 'abstractive': ['Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities.', 'Agent is asking to move to DM and look into it.']}, {'extractive': [{'tweet_id': 87076, 'sentence_offset': '[0, 140]'}, {'tweet_id': 87074, 'sentence_offset': '[41, 139]'}], 'abstractive': ['The customer has a problem.', 'The agent in a very professional way tries to help the client.']}, {'extractive': [{'tweet_id': 87076, 'sentence_offset': '[0, 140]'}, {'tweet_id': 87072, 'sentence_offset': '[19, 87]'}, {'tweet_id': 87069, 'sentence_offset': '[0, 72]'}, {'tweet_id': 87068, 'sentence_offset': '[0, 55]'}], 'abstractive': ['Health and activity functions are not working with the smartwatch and phone.', 'Asks if the customer had restarted the items, offers to take this to DM to help resolve the issue.']}]\n"
     ]
    }
   ],
   "source": [
    "# each dialogue is a dictionary with the following keys:\n",
    "print(train_tw[0].keys())\n",
    "for k in train_tw[0].keys():\n",
    "    print(k,\":\", (train_tw[0][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135060 : So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD\n",
      "135060 : @AppleSupport please read the above.\n",
      "AppleSupport : @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\n",
      "135060 : @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\n",
      "AppleSupport : @135060 Thank you. Have you tried restarting both devices since this started happening?\n",
      "135060 : @AppleSupport I’ve restarted both, also un-paired then re-paired the watch.\n",
      "AppleSupport : @135060 Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\n",
      "135060 : @AppleSupport Yes, everything seems fine, it’s just Health and activity.\n",
      "AppleSupport : @135060 Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? https://t.co/GDrqU22YpT\n",
      "\n",
      "['Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities.', 'Agent is asking to move to DM and look into it.']\n",
      "['The customer has a problem.', 'The agent in a very professional way tries to help the client.']\n",
      "['Health and activity functions are not working with the smartwatch and phone.', 'Asks if the customer had restarted the items, offers to take this to DM to help resolve the issue.']\n"
     ]
    }
   ],
   "source": [
    "# example:\n",
    "# retrieve a conversation and ist abstractive summaries:\n",
    "dialogue_number = 0\n",
    "\n",
    "print('retrieved conversation:')\n",
    "for dic in train_tw[dialogue_number]['tweet_ids_sentence_offset']:\n",
    "    id=dic['tweet_id']\n",
    "    print(df[df['tweet_id']==id]['author_id'].values[0], ':', df[df['tweet_id']==id]['text'].values[0])\n",
    "\n",
    "print()\n",
    "print('abstractive summaries:')\n",
    "for dic in train_tw[dialogue_number]['annotations']:\n",
    "    print(dic['abstractive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_dialogue(split, dialogue_number):\n",
    "    dialog = []\n",
    "    for dic in split[dialogue_number]['tweet_ids_sentence_offset']:\n",
    "        id=dic['tweet_id']\n",
    "        author_id = df[df['tweet_id']==id]['author_id'].values[0]\n",
    "        sentences = df[df['tweet_id']==id]['text'].values[0]\n",
    "        for sentence in sentences:\n",
    "            dialog.append({'sentence':sentence, 'author_id':author_id})\n",
    "    return dialog\n",
    "\n",
    "def retrieve_summary(split, dialogue_number, number_of_summaries='all'):\n",
    "    summaries = []\n",
    "    for dic in split[dialogue_number]['annotations']:\n",
    "        summaries.append(dic['abstractive'])\n",
    "        if len(summaries) == number_of_summaries:\n",
    "            break\n",
    "    if number_of_summaries == 1:\n",
    "        return summaries[0]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the keys of the dictionaries as train_0, train_1, ...test_0, test_1, ...val_0, val_1, ...\n",
    "train_dict_key = {train_tw[i]['conversation_id']: 'train_'+str(i) for i in range(len(train_tw))}\n",
    "test_dict_key = {test_tw[i]['conversation_id']: 'test_'+str(i) for i in range(len(test_tw))}\n",
    "val_dict_key = {val_tw[i]['conversation_id']: 'val_'+str(i) for i in range(len(val_tw))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve all the dialogues and summaries of train/test/val\n",
    "def retrieve_all_dialogues(split):\n",
    "    dialogs = {}\n",
    "    summaries = {}\n",
    "    if split==train_tw:key_dict = train_dict_key\n",
    "    elif split==test_tw: key_dict = test_dict_key\n",
    "    elif split==val_tw: key_dict = val_dict_key\n",
    "    else: raise ValueError(\"split must be train_tw, test_tw or val_tw\")\n",
    "    for i in tqdm(range(len(split))):\n",
    "        k = split[i]['conversation_id']\n",
    "        conv_id = key_dict[k]\n",
    "        dialogs[conv_id]= retrieve_dialogue(split, i)\n",
    "        summaries[conv_id]= retrieve_summary(split, i, 1) # only one summary per dialogue\n",
    "    return dialogs, summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [01:48<00:00,  8.10it/s]\n",
      "100%|██████████| 110/110 [00:12<00:00,  8.68it/s]\n",
      "100%|██████████| 110/110 [00:12<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dialogs, train_summaries = retrieve_all_dialogues(train_tw)\n",
    "test_dialogs, test_summaries = retrieve_all_dialogues(test_tw)\n",
    "val_dialogs, val_summaries = retrieve_all_dialogues(val_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the file path where you want to save the JSON data\n",
    "json_file_paths = \"datasets/processed_tweetsumm_data/train_dialogs.json\", \"datasets/processed_tweetsumm_data/train_summaries.json\", \"datasets/processed_tweetsumm_data/test_dialogs.json\", \"datasets/processed_tweetsumm_data/test_summaries.json\", \"datasets/prprocessed_tweetsumm_dataocess_data/val_dialogs.json\", \"datasets/process_dprocessed_tweetsumm_dataata/val_summaries.json\"\n",
    "data_to_save = [train_dialogs, train_summaries, test_dialogs, test_summaries, val_dialogs, val_summaries]\n",
    "\n",
    "# Open the file in write mode and use json.dump to save the data\n",
    "for json_file_path, data_to_save in zip(json_file_paths, data_to_save):\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data_to_save, json_file)\n",
    "    print(f'file saved at {json_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
